<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!--
  <script src="./resources/jsapi" type="text/javascript"></script>
  <script type="text/javascript" async>google.load("jquery", "1.3.2");</script>
 -->


<style type="text/css">
  @font-face {
   font-family: 'Avenir Book';
   src: url("./fonts/Avenir_Book.ttf"); /* File to be stored at your site */
   }

  body {
    font-family: "Avenir Book", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight:300;
    font-size:14px;
    margin-left: auto;
    margin-right: auto;
    width: 800px;
  }
  h1 {
    font-weight:300;
  }
  h2 {
    font-weight:300;
  }

  p {
    font-weight:300;
    line-height: 1.4;
  }

  code {
    font-size: 0.8rem;
    margin: 0 0.2rem;
    padding: 0.5rem 0.8rem;
    white-space: nowrap;
    background: #efefef;
    border: 1px solid #d3d3d3;
    color: #000000;
    border-radius: 3px;
  }

  pre > code {
    display: block;
    white-space: pre;
    line-height: 1.5;
    padding: 0;
    margin: 0;
  }

  pre.prettyprint > code {
    border: none;
  }



  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.rounded {
    border: 0px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;

  }

  a:link,a:visited
  {
    color: #1367a7;
    text-decoration: none;
  }
  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
            15px 15px 0 0px #fff, /* The fourth layer */
            15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
            20px 20px 0 0px #fff, /* The fifth layer */
            20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
            25px 25px 0 0px #fff, /* The fifth layer */
            25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
      top: 50%;
      transform: translateY(-50%);
  }

  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
</style>



    <title>The Low-Rank Simplicity Bias in Deep Networks</title>
 </head>

  <body>
        <br>
          <center>
		  <span style="font-size:32px">The Low-Rank Simplicity Bias in Deep Networks</span><br><br><br>
          </center>
          <table align="center" width="800px">
            <tbody><tr>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="http://minyounghuh.com">Minyoung Huh</a><sup>1</sup></span>
                </center>
                </td>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://richzhang.github.io/">Hossein Mobahi</a><sup>2</sup></span>
                </center>
                </td>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://richzhang.github.io/">Richard Zhang</a><sup>3</sup></span>
                </center>
                </td>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://richzhang.github.io/">Brian Cheung</a><sup>1 4</sup></span>
                </center>
                </td>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="http://people.csail.mit.edu/sparis/">Pulkit Agrawal</a><sup>1</sup></span>
                </center>
                </td>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://www.dgp.toronto.edu/~hertzman/">Phillip Isola</a><sup>1</sup></span>
                </center>
            </tr>

        </tbody></table><br>

          <table align="center" width="700px">
            <tbody><tr>
                    <td align="center" width="50px">
              <center>
                    <span style="font-size:16px"></span>
                </center>
                </td>
                    <td align="center" width="250px">
              <center>
                    <span style="font-size:16px"><sup>1</sup>MIT CSAIL</span>
                </center>
                </td>
                    <td align="center" width="250px">
              <center>
                    <span style="font-size:16px"><sup>2</sup>Google Research</span>
                </center>
                </td>
                    <td align="center" width="250px">
              <center>
                    <span style="font-size:16px"><sup>3</sup>Adobe Research</span>
                </center>
                </td>
                    <td align="center" width="250px">
              <center>
                    <span style="font-size:16px"><sup>4</sup>MIT BCS</span>
                </center>
                </td>
                    <td align="center" width="50px">
              <center>
                    <span style="font-size:16px"></span>
                </center>
                </td>
        </tr></tbody></table>
          <table align="center" width="700px">
            <tbody><tr>
              <td align="center" width="200px">
                <center>
                  <br>
                  <span style="font-size:20px">Code
                    <a href="#"> [GitHub]</a>
                  </span>
                </center>
              </td>

              <td align="center" width="200px">
                <center>
                  <br>
                  <span style="font-size:20px">
                    Paper <a href="#"> [arXiv]</a>
                  </span>
                </center>
              </td>


              <td align="center" width="200px">
                <center>
                  <br>
                  <span style="font-size:20px">
                    Cite <a href="./cite.txt"> [BibTeX]</a>
                  </span>
                </center>
              </td>

            </tr></tbody>
          </table>

        <br><hr>
        <center>
          <h2>
            Abstract
          </h2>
        </center>
        <p>
        <left>
          Modern deep neural networks are highly over-parameterized compared to the data on which they are trained,
          yet they often generalize remarkably well. A flurry of recent work has asked: why do deep networks not overfit to their training data?
          We investigate the hypothesis that deeper nets are implicitly biased to find lower rank solutions, and these are solutions that generalize well.
          We prove that the percent volume of low effective-rank solutions increases monotonically as linear neural networks are made deeper.
          We empirically find that a similar result holds for non-linear networks: deeper non-linear networks learn a feature space whose kernel has a lower rank.
          We then demonstrate how linear over-parameterization of deep non-linear models can be used to induce low-rank bias,
          improving generalization performance without changing model capacity.
          We evaluate on various model architectures and demonstrate that linearly over-parameterized models outperform existing baselines on image classification tasks, including ImageNet.
        </left>
      </p>
      <br>

      <hr>
      <center> <h2> Results </h2> </center>
      <p><b>Insight 1</b>: <u>The volume of low-rank functions induced by the network parameters increase as a function of the number of layers.</u></p>
      <p>There exists more probability mass for lower-rank rank solutions when adding more layers. The effective rank is computed on the effective weights for linear networks, and on the kernel for non-linear networks.</p>
      <p><img class="rounded"  src="./images/erank-pdf.png" width="800px"></p>

      <br><br>
      <p><b>Insight 2</b>: <u>The parameterization of the network ultimately determine which solution the model will converge to.</u></p>
      <p>In low-rank under-determined regime, models with the same training error results in different test-error. Too shallow or too deep networks perfroms sub-optimally.
      On the contrary, if the underlying solution is full-rank, deep models fail to converge.</p>
      <p><img class="rounded"  src="./images/init-final-magma.png" width="800px"></p>

      <br><br>
      <p><b>Insight 3</b>: <u>Linear over-parameterization of non-linear networks can be used as an implict rank regularizer without increasing the modeling capacity, improving generalization performance thereby. </u>
      <p> Singular values of a CNN for both original (left) and linearly over-parameterized (right) model throughout training.
        The model is over-parameterized by a factor of 4.
        The over-parameterized model exhibits less overfitting, with lower training accuracy and higher testing accuracy. </p>

      <p><img class="rounded"  src="./images/sv-dynamics.png" width="800px"></p>

      <br>
      <hr>
      <center> <h2> Try our PyTorch code </h2> </center>
      Install our code <a href="https://github.com/minyoungg/overparam-layers"> [github] </a>
      <pre><code>
      <font color="00509d">>>></font> <font color="1a936f">git clone</font> https://github.com/minyoungg/overparam-layers
      <font color="00509d">>>></font> <font color="1a936f">cd</font> overparam-layers
      <font color="00509d">>>></font> <font color="1a936f">pip install</font> .
      </code></pre>

      Integrate to your existing PyTorch code base
      <pre><code>
      <font color="ef476f">from</font> overparam <font color="ef476f">import</font> OverparamLinear, OverparamConv2d

      # over-parameterized nn.Linear layer
      layer = <font color="118ab2">OverparamLinear</font>(<font color="f77f00">32, 32, depth=4</font>)

      # over-parameterized nn.Conv2d layer (3 layers with 3x3, 3x3, 1x1 kernels)
      layer = <font color="118ab2">OverparamConv2d</font>(<font color="f77f00">32, 64, kernel_sizes=(3, 3, 1), stride=1, padding=1</font>)
      </code></pre>

      Automatically linear over-parameterize existing models
      <pre><code>
      <font color="ef476f">import</font> torchvision.models as models
      <font color="ef476f">from</font> overparam.utils <font color="ef476f">import</font> overparameterize

      model = models.alexnet()
      model = <font color="118ab2">overparameterize</font>(<font color="f77f00">model, depth=2</font>)
      </code></pre>

      <hr>
      <center> <h2> Acknowledgements </h2> </center>
      <p> We would like to thank Anurag Ajay, Lucy Chai, Tongzhou Wang, and Yen-Chen Lin for reading over the manuscript and Jeffrey Pennington and Alexei A. Efros for fruitful discussions.
          Minyoung Huh is funded by DARPA Machine Common Sense and MIT STL. Brian Cheung is funded by an MIT BCS Fellowship.
          <br><br>

          This research was also partly sponsored by the United States Air Force Research Laboratory and the United States Air Force Artificial Intelligence Accelerator and was accomplished under Cooperative Agreement Number FA8750-19-2-1000.
          The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the United States Air Force or the U.S. Government.
          The U.S. Government is authorized to reproduce and distribute reprints for Government purposes, notwithstanding any copyright notation herein.

          <br> <br>
          <a href="https://richzhang.github.io/colorization/">Website template edited from Colorful Colorization</a>.
      </p>
      <br>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-70157890-3"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-70157890-3');
  </script>


</body></html>
